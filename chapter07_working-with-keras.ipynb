{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyOhFKBOVCmI"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyEBvkaCVCmO"
      },
      "source": [
        "# Working with Keras: A deep dive\n",
        "- The previous chapters used Sequential model,  dense layers, and built-in APIs for training, evaluation, and inference using, respectively, compile(), fit(), evaluate(), predict().\n",
        "\n",
        "- Complex applications in computer vision, time series forecasting, natural language processing, and deep generative models require more than sequential architecture and the default fit() loop.\n",
        "\n",
        "- This chapter will provide a complete overview of key ways of working with Keras API that would be needed for handling advanced deep learning use cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIe3nUN5VCmP"
      },
      "source": [
        "## A spectrum of workflows\n",
        "- Keras API is designed on the principle of *progressive disclosure of complexity*. It is easy to get started on, but progressively goes on to handle complex use cases.\n",
        "\n",
        "- Instead of a single \"true\" way of using Keras, it offers a *spectrum of workflows*, and the compoenents from any workflow can be used in any other workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqWW2ciMVCmP"
      },
      "source": [
        "## Different ways to build Keras models\n",
        "There are three APIs for building models in Keras.\n",
        "- The **Sequential model**, the most approachable API, is just a Python list, and is limited to simple stack of layers.\n",
        "- The **Functional API** focuses on graph-like architecture, and offers a nice middle grounds -- in terms of usability and flexibility. It is the most widely used API.\n",
        "- **Model subclassing** is a low level option where you write everything from stratch. The complete control comes at the cost of non-availability of built-in Keras features nad the risk fo making mistakes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZksO4pvVCmQ"
      },
      "source": [
        "### The Sequential model\n",
        "This is the simplest way to build a Keras model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVZj4_z5VCmR"
      },
      "source": [
        "**The `Sequential` class**\n",
        "\n",
        "We buid a model with two dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yflVfI69VCmS"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prIZnFQVVCmU"
      },
      "source": [
        "**Incrementally building a Sequential model**\n",
        "\n",
        "We could have also built this model incrementally by using the add() method, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BHcMYbbVVCmU"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlGerxMZVCmV"
      },
      "source": [
        "**Calling a model for the first time to build it**\n",
        "- The model has no data yet. So the shape of the weights matrices cannot be known at this time because it depends on shape of the input.\n",
        "- The layers will get built when you use the build() method and supply the input shape.\n",
        "- Below we specify input shape as ('None', 3) which means we have 3 input variables and the 'None' dimension signals that the batch-size could be anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNoMbLuEVCmW"
      },
      "outputs": [],
      "source": [
        "model.build(input_shape=(None, 3))    \n",
        "model.weights\n",
        "\n",
        "# Note: The 'None' argument in the input_shape means\n",
        "# Note: Output below is deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzUJ9BMSVCmW"
      },
      "source": [
        "**The summary method**\n",
        "\n",
        "After building the model, the summary() method will display a summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJZqxUbiVCmX",
        "outputId": "f5b3ad8e-d075-4bf6-ece9-8e7983f2dcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjmCAHZ_VCmX"
      },
      "source": [
        "**Naming models and layers with the `name` argument**\n",
        "\n",
        "- Instead of letting Keras give default names such as 'Dense_1\" to layers, both the <font color='blue'> layer name</font> and the <font color='blue'>model name</font> can be user-specified. See below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wJmiXwBVCmY",
        "outputId": "e659bfbc-2f6e-4df7-d1fa-07ec0369c181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_example_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_first_layer (Dense)      (None, 64)                256       \n",
            "                                                                 \n",
            " my_last_layer (Dense)       (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(name=\"my_example_model\")\n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
        "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
        "model.build((None, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7LADKf2VCmY"
      },
      "source": [
        "**Specifying the input shape of your model in advance**\n",
        "\n",
        "- The input shape can be specified upfront in the Keras  sequential model, using model.add(). This has the advantage that we can see the output shape changes as we add more layers to the sequential model. This can be done by using summary() after every layer.\n",
        "- The cell below specifies the input shape and a dense layer (with 64 units).\n",
        "- This would allow getting output shape after adding the first layer by using summary().\n",
        "- The subsequent cells will add more layers and get output shape using  summary() again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zX21oR5QVCmY"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(3,)))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMLOLppEVCmZ",
        "outputId": "6dd36136-16ff-4bcb-bc3a-0b1eb252226d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256\n",
            "Trainable params: 256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# getting output shape with only the 1st layer\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK4lFeLyVCmZ",
        "outputId": "d1005b0d-2f06-4158-9c47-01b6811ed37f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# adding 2nd layer (softmax), getting output shape\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0bjJ0XJVCmZ"
      },
      "source": [
        "### The Functional API\n",
        "- The Sequential API is easy to use but it can handle only the models with one input and one output. Its applicability is limited.\n",
        "- Models may have multiple inputs (image data and its metadata) and multiple outputs (different things you want to predict about data) or a nonlinear topology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtpdB1hWVCma"
      },
      "source": [
        "#### A simple example\n",
        "This example uses the <font color='blue'>functional API</font> to implement the two-layer model from the previous section "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yAvjNqIVCma"
      },
      "source": [
        "**A simple Functional model with two `Dense` layers**\n",
        "- First, an <font color='blue'>'inputs' object</font> is created by a sybolic input tensor with shape (3,).\n",
        "- The inputs object is passed on to a dense layer (64 units, relu) that creates a features object.\n",
        "- The <font color='blue'>'features' object</font> is passed on to another dense layer (10 units, softmax) that creates an <font color='blue'>'outputs' object</font>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ac7qz3BxVCma"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Lets recreate the inputs, features, and outputs objects so that their shapes and dtype can be found.\n",
        "\n",
        "\n",
        "> In the end, model summary is generated."
      ],
      "metadata": {
        "id": "84x_LQF-otix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kOxDqWaGVCmb"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(3,), name=\"my_input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqv5favLVCmb",
        "outputId": "9fd8ea2e-0b10-45dd-b410-e0cbe8d646da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgCoY35dVCmb",
        "outputId": "02c6275a-3241-46c6-939c-08f9410c1032"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "inputs.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3bNvFwCrVCmb"
      },
      "outputs": [],
      "source": [
        "features = layers.Dense(64, activation=\"relu\")(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Wn_mlHVCmc",
        "outputId": "f78e9ce6-3a4a-4ada-88c6-494fab0a1be2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3fwp1Dq3VCmc"
      },
      "outputs": [],
      "source": [
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R99ZZhWCVCmc",
        "outputId": "e271a177-4780-4131-e9b0-418b55e5db3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_input (InputLayer)       [(None, 3)]               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                256       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 906\n",
            "Trainable params: 906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrVY84aFVCmc"
      },
      "source": [
        "#### Multi-input, multi-output models\n",
        "The functional API is best suited for multi-input, multi-output models. \n",
        "\n",
        "Use case: Building a system for ranking customers' tickets by priority and routing them to appropriate department.\n",
        "\n",
        "The model has three inputs\n",
        "\n",
        "- *The title of the ticket (text input)*\n",
        "- *The text body of the ticket (text input)*\n",
        "- *Any tags added by the user (categorical input, assumed to be one-hot encoded)*\n",
        "\n",
        "There are two outputs\n",
        "- *Priority score of the ticket, a scalar between 0 and 1 (sigmoid output)*\n",
        "- *The department that should handle the ticket (a softmax over the set of departments)*\n",
        "\n",
        "<font color='blue'>Below, this model will be built with a Functional API</font>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hkUQRpdVCmc"
      },
      "source": [
        "**A multi-input, multi-output Functional model**\n",
        "\n",
        "Preprocessing involves setting a vocabolary size of 10,000 words for textual data, setting the number of tags in the ticket text to 100, and setting the number of Departments to 4. \n",
        "\n",
        "The model definition involves the following steps:\n",
        "- Define model inputs\n",
        "- Combine input features into a single tensor, *features*, by concatenating them\n",
        "- Apply intermediate layer to recombine input features into richer representations (pass features to Dense layer)\n",
        "- Define model outputs\n",
        "- Create model by specifying its inputs and outputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwMrl6EUVCmd"
      },
      "outputs": [],
      "source": [
        "vocabulary_size = 10000\n",
        "num_tags = 100\n",
        "num_departments = 4\n",
        "\n",
        "# model inputs\n",
        "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
        "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
        "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
        "\n",
        "# recombining inputs into features \n",
        "features = layers.Concatenate()([title, text_body, tags])\n",
        "features = layers.Dense(64, activation=\"relu\")(features)\n",
        "\n",
        "# model inputs:  ticket priority & the Department to which ticket is routed\n",
        "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
        "department = layers.Dense(\n",
        "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
        "\n",
        "# creating the model\n",
        "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYVX6mI4VCmd"
      },
      "source": [
        "#### Training a multi-input, multi-output model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A46xHhYLVCmd"
      },
      "source": [
        "**Training a model by providing lists of input & target arrays**\n",
        "\n",
        "The training process involves:\n",
        "- Initializing inputs as lists of random integers of dimensions (num_samples, vocabulary_size) with integers in (0,2) i.e as lists of 1's and 0's.\n",
        "- Initializing outputs\n",
        "- Compiling the model -specifying the multioutput  loss function with two loss metrics MSE and categorical cross entropy, corresponding respectively to outputs priority and department; two corresponding performance metrics (respectively, MAE and accuracy).\n",
        "- Fitting the model to data\n",
        "- Evaluation the model\n",
        "- Making predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4jvxnUPVCme"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1280\n",
        "\n",
        "# initializing inputs \n",
        "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
        "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
        "\n",
        "#initializing outputs\n",
        "priority_data = np.random.random(size=(num_samples, 1))\n",
        "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
        "model.fit([title_data, text_body_data, tags_data],\n",
        "          [priority_data, department_data],\n",
        "          epochs=1)\n",
        "model.evaluate([title_data, text_body_data, tags_data],\n",
        "               [priority_data, department_data])\n",
        "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHV8gfQjVCme"
      },
      "source": [
        "**Training a model by providing dicts of input & target arrays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh2tch7-VCme"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
        "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
        "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "          {\"priority\": priority_data, \"department\": department_data},\n",
        "          epochs=1)\n",
        "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
        "               {\"priority\": priority_data, \"department\": department_data})\n",
        "priority_preds, department_preds = model.predict(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7va1cHlVCmf"
      },
      "source": [
        "#### The power of the Functional API: Access to layer connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0MAy6BAVCmf"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw0ZEivxVCmf"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Nuj0NgVCmf"
      },
      "source": [
        "**Retrieving the inputs or outputs of a layer in a Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcWhsHDAVCmf"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuxRka7bVCmf"
      },
      "outputs": [],
      "source": [
        "model.layers[3].input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZa3-3rgVCmg"
      },
      "outputs": [],
      "source": [
        "model.layers[3].output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmI83ogCVCmg"
      },
      "source": [
        "**Creating a new model by reusing intermediate layer outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkjQPM3WVCmh"
      },
      "outputs": [],
      "source": [
        "features = model.layers[4].output\n",
        "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
        "\n",
        "new_model = keras.Model(\n",
        "    inputs=[title, text_body, tags],\n",
        "    outputs=[priority, department, difficulty])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FmhnmNkVCmh"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8hth_ehVCmh"
      },
      "source": [
        "### Subclassing the Model class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWx33VOsVCmh"
      },
      "source": [
        "#### Rewriting our previous example as a subclassed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qZsrz1PVCmh"
      },
      "source": [
        "**A simple subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TNJ_cRZVCmh"
      },
      "outputs": [],
      "source": [
        "class CustomerTicketModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_departments):\n",
        "        super().__init__()\n",
        "        self.concat_layer = layers.Concatenate()\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.department_classifier = layers.Dense(\n",
        "            num_departments, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        title = inputs[\"title\"]\n",
        "        text_body = inputs[\"text_body\"]\n",
        "        tags = inputs[\"tags\"]\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags])\n",
        "        features = self.mixing_layer(features)\n",
        "        priority = self.priority_scorer(features)\n",
        "        department = self.department_classifier(features)\n",
        "        return priority, department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwHZk_vDVCmi"
      },
      "outputs": [],
      "source": [
        "model = CustomerTicketModel(num_departments=4)\n",
        "\n",
        "priority, department = model(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30v_h2nXVCmi"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
        "model.fit({\"title\": title_data,\n",
        "           \"text_body\": text_body_data,\n",
        "           \"tags\": tags_data},\n",
        "          [priority_data, department_data],\n",
        "          epochs=1)\n",
        "model.evaluate({\"title\": title_data,\n",
        "                \"text_body\": text_body_data,\n",
        "                \"tags\": tags_data},\n",
        "               [priority_data, department_data])\n",
        "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
        "                                                  \"text_body\": text_body_data,\n",
        "                                                  \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHiWl3rjVCmi"
      },
      "source": [
        "#### Beware: What subclassed models don't support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqjXYeqiVCmi"
      },
      "source": [
        "### Mixing and matching different components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gQWzYFjVCmj"
      },
      "source": [
        "**Creating a Functional model that includes a subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3QEOhI-VCmj"
      },
      "outputs": [],
      "source": [
        "class Classifier(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        if num_classes == 2:\n",
        "            num_units = 1\n",
        "            activation = \"sigmoid\"\n",
        "        else:\n",
        "            num_units = num_classes\n",
        "            activation = \"softmax\"\n",
        "        self.dense = layers.Dense(num_units, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = Classifier(num_classes=10)(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DwF51DzVCmj"
      },
      "source": [
        "**Creating a subclassed model that includes a Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMZ8akvYVCmj"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(64,))\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
        "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.dense = layers.Dense(64, activation=\"relu\")\n",
        "        self.classifier = binary_classifier\n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.dense(inputs)\n",
        "        return self.classifier(features)\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEXRlYX0VCmj"
      },
      "source": [
        "### Remember: Use the right tool for the job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTZptCOxVCmk"
      },
      "source": [
        "## Using built-in training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCPE9ZmfVCmk"
      },
      "source": [
        "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGHhNMLEVCmk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]\n",
        "\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFDhEjWzVCmk"
      },
      "source": [
        "### Writing your own metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRIWedwVCmk"
      },
      "source": [
        "**Implementing a custom metric by subclassing the `Metric` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYAQ6ekfVCml"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(\n",
        "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        num_samples = tf.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ7pVq5WVCml"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LwJ0y4aVCml"
      },
      "source": [
        "### Using callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dj1snnnVCml"
      },
      "source": [
        "#### The EarlyStopping and ModelCheckpoint callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdDxUlJeVCml"
      },
      "source": [
        "**Using the `callbacks` argument in the `fit()` method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPt-51ZUVCmm"
      },
      "outputs": [],
      "source": [
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=2,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"checkpoint_path.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLZBXRdVCmm"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn4Y4KPwVCmm"
      },
      "source": [
        "### Writing your own callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qh-I3R8VCmm"
      },
      "source": [
        "**Creating a custom callback by subclassing the `Callback` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EpkukQiVCmm"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.per_batch_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        plt.clf()\n",
        "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
        "                 label=\"Training loss for each batch\")\n",
        "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
        "        self.per_batch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ump1NlXVCmn"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=[LossHistory()],\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48GAotWqVCmn"
      },
      "source": [
        "### Monitoring and visualization with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVP_6jdWVCmn"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(\n",
        "    log_dir=\"/full_path_to_your_log_dir\",\n",
        ")\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          validation_data=(val_images, val_labels),\n",
        "          callbacks=[tensorboard])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJDF7jjdVCmn"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /full_path_to_your_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Url2xaMVCmn"
      },
      "source": [
        "## Writing your own training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OISvJ9OVCmo"
      },
      "source": [
        "### Training versus inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gRuX8QSVCmo"
      },
      "source": [
        "### Low-level usage of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3HBbTfiVCmo"
      },
      "outputs": [],
      "source": [
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "targets = [0, 1, 2]\n",
        "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "metric.update_state(targets, predictions)\n",
        "current_result = metric.result()\n",
        "print(f\"result: {current_result:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn9jOEsvVCmo"
      },
      "outputs": [],
      "source": [
        "values = [0, 1, 2, 3, 4]\n",
        "mean_tracker = keras.metrics.Mean()\n",
        "for value in values:\n",
        "    mean_tracker.update_state(value)\n",
        "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnw3wmYbVCmo"
      },
      "source": [
        "### A complete training and evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSJ8QEqjVCmo"
      },
      "source": [
        "**Writing a step-by-step training loop: the training step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QsiUY6hVCmp"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_tracking_metric = keras.metrics.Mean()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"loss\"] = loss_tracking_metric.result()\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIK-6C5lVCmp"
      },
      "source": [
        "**Writing a step-by-step training loop: resetting the metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGCs4qX8VCmp"
      },
      "outputs": [],
      "source": [
        "def reset_metrics():\n",
        "    for metric in metrics:\n",
        "        metric.reset_state()\n",
        "    loss_tracking_metric.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fWEaIz_VCmp"
      },
      "source": [
        "**Writing a step-by-step training loop: the loop itself**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmeqAEnjVCmp"
      },
      "outputs": [],
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "training_dataset = training_dataset.batch(32)\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    reset_metrics()\n",
        "    for inputs_batch, targets_batch in training_dataset:\n",
        "        logs = train_step(inputs_batch, targets_batch)\n",
        "    print(f\"Results at the end of epoch {epoch}\")\n",
        "    for key, value in logs.items():\n",
        "        print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpB90HkzVCmq"
      },
      "source": [
        "**Writing a step-by-step evaluation loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--3VkJdhVCmq"
      },
      "outputs": [],
      "source": [
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLO1amLOVCmr"
      },
      "source": [
        "### Make it fast with tf.function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR5wzISZVCmr"
      },
      "source": [
        "**Adding a `tf.function` decorator to our evaluation-step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HnNO9O3VCmr"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgPNlzJDVCmr"
      },
      "source": [
        "### Leveraging fit() with a custom training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8-V5DohVCmr"
      },
      "source": [
        "**Implementing a custom training step to use with `fit()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAh8Ku_MVCms"
      },
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = loss_fn(targets, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPXI_22qVCms"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop())\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o62DV9gxVCms"
      },
      "outputs": [],
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, predictions)\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        self.compiled_metrics.update_state(targets, predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDmXD7V0VCms"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIVyqnqhVCms"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chapter07_working-with-keras.i",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}